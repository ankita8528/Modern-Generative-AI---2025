# Fine Tuning an LLM
In this blog we are going to cover the folowing topics:

1. What is Fine Tuning?
3. Why do we need Fine Tuning?
4. When should we use it?
5. Types of Fine Tuning
6. When and When NOT to use Fine Tuning?
7. Some real world usecases
8. Hands on pactice.

---
# What is Fine Tuning?
Suppose you have a pre-trained model like GPT-4 or GPT-3.5. Now imagine this model as a super-smart student who has already read the entire internet — but has never read your specific textbook.

Let’s say you want this student to fully understand your book — whether it's on medicine, engineering, or any other specialized domain.

Now you have two options:

Option A: You teach them everything about medicine from scratch.
Option B: You simply teach them your book to help them grasp your specific content.

If you ask me, I’d go with Option B — because this student already knows a lot about medicine from the internet. You don’t need to start over. You’re just giving them your specialized context.

This saves your time, energy, and the student’s effort as well.

In the same way, when we want GPT-4 to become an expert in law and legal systems, we don’t need to retrain it from scratch on massive legal data. Instead, we fine-tune it on a smaller, domain-specific dataset, which gives it the additional understanding it needs — saving time, compute, and cost.

**Fine-tuning is taking a pre-trained model and training it a little more on your custom dataset so it performs better for your task.** And while you will train the model on your custom dataset, the weights and the biases (aka parameters) of the model will change, this is how any deep learning model is being trained. Example: ChatGPT - fine tuned on the top GPT base models.

---

# Why do we need Fine Tuning?
Now you might be wondering that we can make the LLM to act as an expert in Law-practices with the help of prompting, so why do we need to fine tune specifically. Well here's the answer to your "why". We will understand this with the help of a story.

Imagine you’ve hired a brilliant AI student — let’s call her Maya. Maya has read all the books on the internet, seen every YouTube tutorial, and studied every Wikipedia article. She's super smart.

Now, you want Maya to help you write medical reports for a hospital.

**Day 1: You try prompting (giving her instrauctions)**
You say:

> “Hey Maya, every time I give you patient data, write a report in this exact format. Include vitals, diagnosis, suggested tests, and > always end with ‘Reviewed by Dr. Sharma’.”

Maya nods and does a decent job.

But the next day, you give her a new case, and she forgets the format. She forgets to mention the doctor's name. Sometimes she writes in bullet points. Sometimes in full paragraphs.

So you keep repeating the same instructions:

“Format like this. End with Dr. Sharma. Use technical terms.”

It’s like writing her a sticky note every single time.

**Day 5 — You're Tired**
You're exhausted. You’ve written the same long prompt 50 times. And sometimes Maya still messes up the style or forgets medical abbreviations.

You think:

"She’s brilliant — but I wish she’d just learn how we do things here.”

**So You Fine-Tune Her (train her a bit)**
You spend a weekend with Maya. You show her hundreds of past medical reports from your hospital. You walk her through the patterns, the terminology, the format.

She studies your data closely. You don’t need to teach her everything about medicine — she already knows that. You’re just showing her how you want things done.

This is fine-tuning.

Now, Maya doesn’t need sticky notes anymore.

**Week Later — She’s Fluent**
Now Maya produces flawless medical reports in seconds. She uses your preferred vocabulary, follows your templates, and never forgets “Reviewed by Dr. Sharma.”

She understands the vibe. She’s customized. She's fast. And you no longer need to remind her how to behave.

**Moral of the Story**

***Prompting*** is like giving ***instructions*** to a brilliant but forgetful assistant — works for short-term, but not always reliable.

***Fine-tuning*** is like ***training*** that assistant to work your way, so she just knows what to do — permanently.

So even though Maya is a genius who read the whole internet, she still needs fine-tuning to truly work for you.

**Real World Analogy**

Prompting = Giving a note to a waiter each time: “No onions in my dish.”

Fine-tuning = Training the waiter to remember your preference every time you visit.

Prompting works for one-time or varied tasks.
Fine-tuning is better when you want consistency, efficiency, or specialization.

### Finals thoughts on why fine tuning is better than prompting

1. Domain Adaption: If your data is domain-specific (e.g., medical, legal, finance), prompts may not be enough to make the model behave well. Fine-tuning makes it fluent in your domain.
2. Behavior Control: You want the model to act in a specific way: Always polite, Always output JSON, Follow certain formats strictly. Prompting might fail inconsistently. Fine-tuning bakes the behavior in.
3. Efficiency at Scale: If you’re doing millions of requests, long prompts cost more (tokens = money). Fine-tuned models need shorter prompts and are faster to run.
4. RAG + Fine-Tuning = 🔥: Even in Retrieval-Augmented Generation (RAG), fine-tuning can:
   - Improve grounding
   - Help model reason better with the documents
   - Reduce hallucinations
5. Few-Shot is Expensive, Fine-Tune is Scalable: Prompting with 5–10 examples ("few-shot") eats up context length. Fine-tuning is like giving those examples once, and then the model learns them forever. 

